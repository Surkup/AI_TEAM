# Протокол ревизии Storage и Context/Memory

**Статус**: Draft for review (концептуальный документ)
**Дата**: 2025-12-19
**Автор**: ChatGPT (экспертная ревизия по итогам обсуждений AI_TEAM)
**Источник**: Внешняя экспертиза архитектуры

---

## Назначение документа

Данный документ фиксирует экспертный анализ архитектуры памяти и хранилища AI_TEAM.
Он предназначен для:
1. Привязки Storage к обсуждённой архитектуре памяти
2. Чек-листа требований для ревизии ТЗ на Storage
3. Фиксации рисков и направлений будущего развития

---

## Часть 1. Ключевая суть: разделение ответственности

### 1.1. Контекст проблемы

В проекте AI_TEAM утверждена ключевая архитектурная парадигма:
**State outside the model** (Состояние вне модели).

LLM/агенты не "помнят" проект сами по себе — память и состояние должны быть вынесены
во внешние системные узлы (Canon/Memory/History/Context Pack и т.д.).

### 1.2. Определения (словарь)

| Термин | Определение |
|--------|-------------|
| **Storage** | "Тупой" надёжный слой артефактов. Хранит файлы/бинарные данные/исходники. Не делает выводов и не "интерпретирует". |
| **Canon** | Утверждённая "истина" проекта: правила, факты, спецификации, решения. Canon должен ССЫЛАТЬСЯ на артефакты, но не зависеть от изменяемых файлов. |
| **Memory / Knowledge Store** | Поисковая/семантическая память (vector store, индексы) + структурные знания, поддерживающие retrieval (RAG) и сборку контекста. |
| **History** | Хронологический журнал событий/решений/обсуждений/шагов выполнения задач. |
| **Context Pack** | Оперативный пакет данных "на сейчас" для конкретного шага/команды, собранный Оркестратором. Он маленький, релевантный и управляет стоимостью токенов. |
| **Global Commons** | Паттерны, системные промпты, практики, шаблоны — общие для всех проектов. Важно: не содержит проектных данных. |

### 1.3. Роль Storage в архитектуре AI_TEAM

Storage — это НЕ "память" в смысле знаний. Storage — это фундаментальный слой "raw data" и артефактов:
- исходные файлы, черновики, экспортированные результаты
- большие данные (видео/аудио/датасеты), которые нельзя держать в контексте LLM
- доказательства (evidence) для Canon и решений

**Канонический принцип:**
> Storage хранит. Canon утверждает. Memory индексирует. Orchestrator собирает Context Pack.

Агент НЕ должен "произвольно перечитывать Storage" как источник истины — он получает выдержки/ссылки/контексты.

---

## Часть 2. Детальные требования для ревизии ТЗ на Storage

### 2.1. Изоляция проектов и пространства имён (Namespaces)

**Проблема:**
Если проекты не изолированы жёстко, память и артефакты будут "просачиваться" между проектами
(пример: ужастик → любовный роман с элементами ужастика).

**Минимальные требования:**
- Каждый объект в Storage принадлежит `project_id` (обязательный namespace)
- Операции чтения/записи/поиска обязаны указывать `project_id`
- Нельзя получить доступ к объекту другого проекта без явного разрешения
- Должна быть возможность архивировать/замораживать проект (read-only режим)

**Вопросы для ТЗ:**
- [ ] Где явно определяется `project_id` и как он участвует в ключах?
- [ ] Что происходит при попытке доступа без `project_id`?
- [ ] Есть ли режим "frozen project" и "archived project"?

---

### 2.2. Immutable артефакты и версионирование (очень важно)

**Проблема:**
Если один и тот же artifact "перезаписывается", Canon начинает ссылаться на меняющуюся сущность,
и SSOT теряет смысл.

**Рекомендованный принцип:**
> **Immutable Artifacts.**
> Файл после сохранения не меняется. Любое изменение = новая версия/новый артефакт.

**Минимальные требования:**
- `artifact_id` уникален и неизменяем
- Версия артефакта фиксируется: `version_id` / `content_hash` / `etag`
- Canon должен ссылаться минимум на `artifact_id + version` (или на `content_hash`)

**Вопросы для ТЗ:**
- [ ] Можно ли "перезаписать" артефакт?
- [ ] Как идентифицируются версии?
- [ ] Может ли Canon ссылаться на "latest"? (желательно: нет, только на конкретную версию)

---

### 2.3. Связь Storage → Canon → Evidence

**Проблема:**
Нужна юридически/логически корректная связка "почему Canon таков":
Canon должен уметь ссылаться на доказательства/источники (raw data).

**Требования:**
- У каждого важного факта/правила в Canon должна быть возможность указать `evidence_ref`:
  `artifact_id`, `version_id`, plus offset/fragment ref (если возможно)
- Storage должен гарантировать доступность evidence (raw) по политике хранения
- При сжатии/summary память не должна терять ссылку на raw

**Практика:**
- "Raw data is immutable"
- "Summary points to raw" (summary → raw reference)

**Вопросы для ТЗ:**
- [ ] Есть ли понятие `evidence_ref`/`links`?
- [ ] Есть ли механизм ссылок на фрагменты (page, timecode, byte-range)?
- [ ] Какие политики retention для evidence?

---

### 2.4. Storage НЕ должен становиться "памятью" (границы ответственности)

**Сильная рекомендация:**
- Storage не должен решать задачи "релевантности" и "подачи контекста" — это роль Memory/Orchestrator
- Агент не должен произвольно "сканировать" Storage, иначе токены и время улетают в космос

**Требования (политические, архитектурные):**
- Агент получает в Context Pack:
  - ссылки (`artifact_id`)
  - короткие выдержки
  - summaries
  - опционально: RAG snippets
- Полный "raw file" читается только по явному решению Orchestrator/Policy

**Вопросы для ТЗ:**
- [ ] Кто имеет право читать полный raw? (agent/orchestrator/memory node)
- [ ] Как ограничиваются опасные операции (delete/overwrite)?
- [ ] Есть ли лимиты на размер выдачи?

---

### 2.5. Жизненный цикл артефакта (Artifact Lifecycle)

**Проблема:**
Без жизненного цикла Storage превращается в свалку: черновики, промежуточные файлы, дубликаты, мусор.

**Рекомендуемые статусы:**
- `draft` (черновик)
- `intermediate` (промежуточный)
- `final` (итоговый)
- `canon-linked` (на него есть ссылка из Canon)
- `archived` (холодное хранение)
- `deleted` (логическое удаление/тумбстоун, если нужно)

**Рекомендуемые метаданные артефакта:**
- `project_id`
- `artifact_id`
- `version_id` / `content_hash`
- `created_at`, `created_by` (node_id)
- `artifact_type` (text/code/video/dataset/config)
- `stage/status` (draft/final/...)
- `tags`
- `relationships`: `parent_artifact_id` (если derived), `source_task_id`, `process_id`, `step_id`

**Вопросы для ТЗ:**
- [ ] Есть ли обязательные метаданные и минимальная схема?
- [ ] Как фиксируется происхождение артефакта (provenance)?
- [ ] Можно ли автоматически помечать "intermediate" и очищать по TTL?

---

### 2.6. Контроль ресурсов и "инспектор" (Storage Curator)

**Проблема:**
Ресурсы не бесконечны. При переполнении без политики система ломается.

**Идея:**
Ввести роль/узел **Storage Curator** (аналог Memory Curator, но другой домен).

**Функции Storage Curator:**
- мониторинг объёма (per project, per type, global)
- политики retention:
  - TTL для временных артефактов
  - архивирование в cold storage
  - запрет удаления canon-linked без процедуры
- дедупликация (по `content_hash`)
- отчёты и предупреждения (events)
- подготовка "compression packages" (например, сжатие видео, конвертация)

**Важно:**
- Curator НЕ имеет права "искажать смысл". Он может оптимизировать хранение, но:
  - хранит ссылки на raw
  - ведёт журнал действий
  - для критичных объектов требует подтверждение (human-in-loop или critic agent)

**Вопросы для ТЗ:**
- [ ] Есть ли лимиты storage budget (per project / global)?
- [ ] Как система узнаёт, что лимит превышен?
- [ ] Есть ли события/алерты о заполнении?
- [ ] Как защищаем canon-linked артефакты от удаления?

---

### 2.7. Дедупликация и конфликтность

**Проблема:**
Мультиагентная среда быстро плодит дубликаты (одно и то же сохранено 10 раз).

**Решения:**
- `content_hash` и индексация на него
- политика: если `content_hash` совпал — не хранить заново, а создавать ссылку
- "artifact aliasing": разные имена/пути могут указывать на один и тот же blob

**Вопросы:**
- [ ] Как определяется дубликат? (hash)
- [ ] Нужно ли различать "логически разные" файлы с одинаковым содержанием?
- [ ] Где хранится индекс hash → artifacts?

---

### 2.8. Безопасность и права (ACL / Policies)

**Проблема:**
Если агентам дать delete/write без ограничений — он может разрушить систему.

**Минимальные правила:**
- роли и права:
  - read-only агенты
  - write-only в свои префиксы
  - delete только через Curator/Orchestrator policy
- audit log на операции (кто/что/когда)

**Вопросы:**
- [ ] Кто имеет право удалять? агент? только orchestrator? только curator?
- [ ] Есть ли неизменяемый audit log?
- [ ] Как выполняется доступ по токенам/ключам?

---

### 2.9. Интеграция с MindBus / MESSAGE_FORMAT (только на уровне событий)

**Принцип:**
Storage — это "control plane via API", а события — "data plane" для наблюдаемости.

**Рекомендация:**
- Операции хранения и чтения лучше делать через API (синхронно)
- После успешной операции Storage может публиковать EVENT:
  - `evt.storage.artifact_created`
  - `evt.storage.artifact_archived`
  - `evt.storage.quota_warning`
  - `evt.storage.artifact_deleted`

**Вопросы:**
- [ ] Есть ли в ТЗ events от storage?
- [ ] Какой source? (storage-node)
- [ ] Какие поля в event_data? (artifact_id, project_id, size, hash, status)

---

### 2.10. Как Storage помогает решать проблему "забывчивости" (но не превращаясь в память)

**Ключ:**
Storage хранит "сырьё", Memory индексирует, Orchestrator собирает Context Pack.

**Практические сценарии:**

**Книга:**
- главы, черновики, персонажи → storage
- канон персонажей (утверждённое) → canon
- embeddings по главам/сводкам → memory store
- context pack: текущая глава + canon snapshot + последние 3 шага + RAG snippets

**Разработка ПО:**
- репо, патчи, логи, тест-репорты → storage
- архитектурные решения/интерфейсы → canon
- семантический индекс по кодовой базе/докам → memory store
- context pack: задача + API контракт + relevant files + recent changes

**Видео:**
- исходники клипов, аудио, таймлайны → storage
- стиль/правила проекта → canon
- индекс по сценариям, сценам, голосу → memory store
- context pack: текущая сцена + стиль + relevant assets refs + constraints

---

## Часть 3. Риски и направления развития

### 3.1. Риск "любовный роман с элементами ужастика"
Если storage/memory/canon не имеют project namespace — смешение неизбежно.
Нужна строгая модель изоляции и явные правила доступа.

### 3.2. Риск "Canon завязан на mutable файлы"
Если артефакты перезаписываются — нарушается SSOT.
Требуется immutable + version pinning.

### 3.3. Риск "Storage превращается в Memory и раздувает токены"
Если агент читает raw без ограничений — стоимость и деградация качества.
Решение: context pack + retrieval + limits + policies.

### 3.4. Риск потери нюансов при компрессии/сжатии
Curator может "упростить" и испортить смысл.
Контрмера: raw сохраняем; summary хранит ссылки; возможен запрос "expand raw".

### 3.5. Версионирование и миграции форматов артефактов
Что делать при переходе на новые форматы (например, json → protobuf, md → docx)?
Нужна стратегия миграции и маркировка `artifact_type + schema_version`.

### 3.6. Политики хранения (Retention) и юридические требования
GDPR/PII, авторские права, приватные данные, лицензии моделей.
В перспективе нужен "compliance mode" для хранения/удаления.

### 3.7. Observability и аудит
Нужны метрики: storage usage, read/write latency, hot/cold access,
top projects by growth, dedupe ratio, number of canon-linked artifacts.
Нужны события/алерты через MindBus.

### 3.8. Storage node как узел системы
Storage node — это узел системы, значит:
- должен иметь Node Passport
- регистрироваться в Node Registry
- поддерживать health/ready status
- публиковать events (опционально)

### 3.9. Уточнение границ Curators
- Memory Curator (энтропия знаний) vs Storage Curator (энтропия файлов)
- Важно не смешать: один отвечает за смысл/противоречия, второй — за хранение/ресурсы

### 3.10. Идея "Global Commons"
Отдельное пространство общих шаблонов, паттернов, best practices:
- доступно всем проектам
- не содержит проектных данных
- помогает переносить навыки без утечки фактов

---

## Приложение A. Компактный чек-лист для ревизии ТЗ на Storage

- [ ] Есть обязательный `project_id` namespace на все операции и объекты?
- [ ] Артефакты immutable? Есть `version_id`/`content_hash`? Есть запрет overwrite?
- [ ] Canon ссылается на `artifact_id + version` (не на mutable latest)?
- [ ] Есть минимальная схема метаданных артефакта (provenance, type, status)?
- [ ] Есть жизненный цикл артефактов (draft/intermediate/final/canon-linked/archived)?
- [ ] Есть политики retention/TTL/архивирование/cold storage?
- [ ] Есть защита canon-linked от удаления?
- [ ] Есть дедупликация по `content_hash`?
- [ ] Ограничены права агентов (delete/write/read raw)?
- [ ] Storage операции через API (sync), а events — для наблюдаемости (async)?
- [ ] Есть quota monitoring и события предупреждения (quota_warning)?
- [ ] Storage node оформлен как Node Passport + Registry (как узел системы)?

---

## Связанные документы

- [STORAGE_SPEC_v1.0.md](../../SSOT/STORAGE_SPEC_v1.0.md) — утверждённая SSOT спецификация
- [STORAGE_ARCHITECTURE_DISCUSSION_2025-12-19.md](./STORAGE_ARCHITECTURE_DISCUSSION_2025-12-19.md) — протокол обсуждения
- [IMPLEMENTATION_ROADMAP.md](../../project/IMPLEMENTATION_ROADMAP.md) — план реализации (Этап 5)

---

*Документ интегрирован: 2025-12-19*
*Источник: экспертная ревизия от ChatGPT*
