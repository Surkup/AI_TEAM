# Список вопросов и идей для проработки

Этот документ содержит все вопросы, идеи и неопределенности, которые возникают при разработке концепции AI_TEAM. На каждом этапе детального проектирования компонентов мы будем возвращаться к соответствующим разделам этого файла.

## Общие принципы работы с этим документом

- Вопросы группируются по компонентам системы
- Каждый вопрос может содержать возможные варианты решений (не как истину в последней инстанции, а как варианты для рассмотрения)
- При разработке технического задания на компонент - обязательно просматриваем соответствующий раздел
- Решенные вопросы помечаются ✅ с указанием решения и ссылкой на документ, где это описано

---

## 1. Orchestrator (Оркестратор)

### 1.1. Регистрация и discovery агентов

**Вопрос**: Как Оркестратор узнает о возможностях новых агентов? Как он понимает, какому агенту можно поручить конкретную задачу?

**Контекст**: При добавлении нового агента в систему, Оркестратор должен понимать его функционал, чтобы правильно распределять задачи.

**Возможные варианты решения**:
- **Профиль агента (резюме)**: По аналогии с HR-процессом - каждый агент при регистрации предоставляет профиль/резюме, где описаны:
  - Специализация (роль)
  - Компетенции и навыки
  - Типы задач, которые может выполнять
  - Инструменты и сервисы, которые использует
  - Входные и выходные форматы данных
- **Реестр агентов**: Центральный реестр (подобие отдела кадров), где хранятся профили всех зарегистрированных агентов
- **Оркестратор обращается к реестру**: При получении задачи Оркестратор запрашивает из реестра список агентов с нужными компетенциями

**Связанные вопросы**:
- Какой формат описания функционала агента? (JSON, YAML, структурированный текст?)
- Как Оркестратор понимает семантику задач? (Например, "создать инфографику" → Designer, а не Writer)
- Нужна ли онтология/таксономия задач и компетенций?
- Как агенты регистрируются? Автоматически при запуске или требуется ручная настройка?

**Приоритет**: Высокий - критично для работы всей системы

---

### 1.2. Сопоставление задач и агентов

**Вопрос**: Как Оркестратор понимает, что новая задача похожа на уже решенную? Когда использовать существующую Process Card, а когда создавать новую?

**Контекст**: Оркестратор анализирует задачу и должен решить - есть ли подходящая Process Card в базе знаний или нужно создать новую.

**Возможные варианты решения**:
- **Семантический поиск**: Использование векторных embedding для поиска похожих задач
- **Категоризация задач**: Задачи относятся к определенным категориям (разработка ПО, создание контента, аналитика и т.д.)
- **Ключевые слова и теги**: Process Cards имеют метаданные для быстрого поиска
- **Обучение на истории**: Оркестратор учится на успешных совпадениях задача-процесс

**Связанные вопросы**:
- Нужна ли семантическая индексация Process Cards?
- Как оценивается степень похожести задач?
- Можно ли модифицировать существующую Process Card под новую задачу или лучше создать новую?

**Приоритет**: Высокий

---

### 1.3. Конфликты ресурсов и приоритеты задач

**Вопрос**: Что происходит при конфликте ресурсов? Как работают приоритеты между задачами?

**Контекст**: Если все агенты заняты, а пришла новая (возможно срочная) задача, система должна принять решение.

**Возможные варианты решения**:
- **Специализированный агент-менеджер конфликтов**: Отдельный компонент, который разрешает конфликты ресурсов
- **Система приоритетов**: Каждая задача имеет приоритет (Critical, High, Medium, Low)
- **Очереди с приоритетами**: Задачи встают в очередь с учетом приоритета
- **Прерывание задач**: Возможность приостановить менее важную задачу в пользу более важной
- **Эскалация человеку**: Если автоматически разрешить конфликт невозможно - система ставит процесс на паузу и запрашивает решение человека

**Вопросы**:
- Может ли человек прервать выполнение одной задачи в пользу другой? **Ответ**: Да, человек - главный руководитель, все процессы ему подчиняются
- Как оценивается "важность" задачи автоматически?
- Можно ли динамически менять приоритеты?
- Как избежать "голодания" низкоприоритетных задач?

**Важное архитектурное решение**: Человек общается только с Оркестратором, а не напрямую с агентами (иерархия как в армии). Это предотвращает путаницу и конфликты команд.

**Приоритет**: Средний - важно, но не критично для MVP

---

### 1.4. Архитектура Оркестратора

**Вопрос**: Не станет ли Оркестратор монолитом? Не стоит ли разбить его на подкомпоненты?

**Контекст**: Оркестратор выполняет множество функций: планирование, координация, контроль качества, управление ресурсами. Это может привести к излишней сложности.

**Возможные варианты решения**:
- **Монолитный Оркестратор**: Все функции в одном компоненте (проще для MVP)
- **Модульный Оркестратор**: Разбивка на подкомпоненты:
  - **Planner** - планирование и выбор Process Cards
  - **Coordinator** - распределение задач между агентами
  - **QualityController** - контроль качества
  - **ResourceManager** - управление ресурсами и конфликтами
- **Микросервисная архитектура**: Каждый подкомпонент - отдельный сервис

**Приоритет**: Средний - для MVP можно начать с монолита, потом разделить

---

### 1.5. Философия управления и принятие решений

**Вопрос**: Какую управленческую философию использует Оркестратор? Как AI-команда принимает решения?

**Контекст**: В реальных компаниях существуют разные модели управления - авторитарная, демократическая, адаптивная. Оркестратор как директор тоже должен иметь четкую философию принятия решений.

**Возможные варианты решения**:
- **Авторитарная модель**: Оркестратор принимает все решения единолично, агенты только исполняют
- **Консультативная модель**: Оркестратор запрашивает мнения у агентов, но решает сам
- **Демократическая модель**: Решения принимаются коллегиально (например, голосование агентов)
- **Адаптивная модель**: Модель управления меняется в зависимости от типа задачи

**Вопросы для проработки**:
- Как балансируется скорость vs качество? (Быстрое решение vs тщательная проработка)
- Как разрешаются конфликты интересов? (Writer хочет скорость, Editor хочет качество)
- Кто имеет право вето при принятии решений?
- Может ли агент оспорить решение Оркестратора?

**Приоритет**: Высокий - это концептуальная основа всей системы управления

---

### 1.6. Самостоятельная корректировка процессов (Self-Correction)

**Вопрос**: Может ли Оркестратор временно отклониться от утвержденной Process Card?

**Контекст**: Оркестратор строго следует Process Card. Но что если Process Card устарела или ведет к ошибке? Должна ли система иметь возможность проявить гибкость?

**Возможные варианты решения**:
- **Строгое следование**: Оркестратор НИКОГДА не отклоняется от Process Card, всегда требует создания новой
- **Гибкость с логированием**: Оркестратор может временно отклониться от процесса на один шаг с обязательным логированием
- **Отклонение с подтверждением**: Оркестратор может запросить у человека разрешение на отклонение
- **Адаптивные процессы**: Process Card содержит "зоны гибкости", где разрешены вариации

**Вопросы для проработки**:
- Как разграничить "небольшое отклонение" от "изменения официальной инструкции"?
- Как система учится на таких отклонениях? (Обновляет ли Process Card автоматически?)
- Нужен ли "режим обучения", где отклонения разрешены?
- Кто ревьюит и утверждает отклонения от процессов?

**Приоритет**: Высокий - баланс между гибкостью и строгостью критичен

---

### 1.7. Роль человека (CEO): границы ответственности

**Вопрос**: Что человек делать НЕ ДОЛЖЕН, чтобы система выполняла свою функцию?

**Контекст**: Чтобы AI_TEAM работал эффективно и автономно, важно определить не только что человек может делать, но и чего делать не стоит (избежать micromanagement).

**Границы ответственности человека**:

**Что человек ДОЛЖЕН делать**:
- Ставить стратегические цели и задачи
- Принимать решения в критических точках (checkpoints)
- Оценивать финальные результаты
- Корректировать направление при необходимости
- Управлять бюджетами и приоритетами

**Чего человек делать НЕ ДОЛЖЕН**:
- Управлять каждым агентом напрямую (только через Оркестратор)
- Вмешиваться в процесс без критической необходимости
- Делать работу за агентов
- Создавать Process Cards вручную (если не эксперт в области)
- Микроменеджить каждый шаг выполнения

**Вопросы для проработки**:
- Как система "мягко подсказывает" человеку, что он слишком вмешивается?
- Нужны ли метрики "здорового делегирования"?
- Как обучать пользователя правильному взаимодействию с системой?

**Приоритет**: Средний - важно для UX и эффективности

---

## 2. AI-Агенты

### 2.1. Agent Pools (Пулы агентов)

**Вопрос**: Как реализовать параллельную работу нескольких агентов одной специализации?

**Контекст**: Для некоторых задач нужно получить несколько вариантов решения от разных исполнителей (например, 3 разных сюжета для книги).

**Возможные варианты решения**:
- **Множественные экземпляры агентов**: В системе зарегистрировано несколько Writer агентов (Writer_1, Writer_2, Writer_3)
- **Динамическое масштабирование**: Оркестратор создает временные копии агентов для параллельной работы
- **Поддержка в Process Cards**: Карточка процесса может указывать "запустить задачу на N агентах параллельно"

**Связанные вопросы**:
- Как агрегировать результаты от нескольких агентов?
- Кто выбирает лучший вариант - другой агент, комиссия или человек?
- Как избежать идентичных результатов (добавлять "температуру" в промпты)?

**Приоритет**: Средний - интересная возможность, но не критична для MVP

---

### 2.2. Изоляция и безопасность агентов

**Вопрос**: Как изолировать выполнение задач агентов для обеспечения безопасности?

**Контекст**: Агенты могут выполнять потенциально опасные операции (запуск кода, работа с файлами). Нужна изоляция.

**Возможные варианты решения**:
- **Sandbox на уровне процесса**: Ограничение прав процесса ОС
- **Контейнеризация (Docker)**: Каждый агент работает в своем контейнере
- **Виртуальные машины**: Полная изоляция через VM (для особо опасных операций)
- **Комбинированный подход**: Разные уровни изоляции для разных типов агентов:
  - Writer/Editor - минимальная изоляция (только текст)
  - Developer - контейнер
  - QA/Tester - выделенная VM с ресурсами

**Связанные вопросы**:
- Как определяется уровень изоляции для каждого агента?
- Кто отвечает за настройку изоляции - разработчик агента или администратор системы?
- Как мониторить использование ресурсов изолированными агентами?

**Приоритет**: Высокий - критично для безопасности

---

### 2.3. Статусы и состояния агентов (динамика)

**Вопрос**: Какие состояния может иметь агент? Как динамика состояний влияет на распределение задач?

**Контекст**: Агенты - это не статичные сущности. Они могут быть заняты, перегружены, требовать обновления. Эти состояния критично важны для Оркестратора при распределении работы.

**Возможные состояния агента**:
- **Доступен (Available)**: Готов принять новую задачу
- **Занят (Busy)**: Выполняет задачу, может принять еще задачи в пределах лимита
- **Перегружен (Overloaded)**: Достиг максимума задач, новые не принимает
- **Недоступен (Unavailable)**: Временно не работает (обновление, ошибка, обслуживание)
- **На паузе (Paused)**: Приостановлен человеком или системой
- **Требует обновления (Update Required)**: Версия устарела, нужна актуализация
- **Требует обучения (Training Required)**: Показатели качества упали, нужна доработка
- **В режиме отладки (Debug Mode)**: Работает с расширенным логированием

**Вопросы для проработки**:
- Как агент сообщает о смене своего статуса? (Активно в MindBus или Оркестратор опрашивает?)
- Как определяется "перегруженность"? (По количеству задач, по времени выполнения, по потреблению ресурсов?)
- Может ли агент сам перейти в паузу? (Например, при обнаружении проблем)
- Как система реагирует на агента в статусе "Требует обучения"?
- Нужна ли история переходов между состояниями для анализа?

**Приоритет**: Высокий - критично для эффективного распределения задач

---

### 2.4. Внутренние метрики агентов ("мотивация" и эволюция)

**Вопрос**: Должны ли агенты иметь внутренние метрики качества своей работы? Могут ли они эволюционировать?

**Контекст**: В продвинутых мультиагентных системах агенты могут иметь внутренние цели и метрики, которые они стремятся оптимизировать. Это не "сознание", а механизм самоулучшения.

**Возможные внутренние метрики по типам агентов**:
- **Writer**: связность текста, читабельность, соответствие стилю
- **Editor**: количество найденных ошибок, точность правок
- **Analyst**: точность прогнозов, полнота данных
- **Researcher**: релевантность источников, полнота покрытия темы
- **Developer**: качество кода, покрытие тестами, производительность

**Возможности эволюции агентов**:
- **Настройка параметров LLM**: Агент может экспериментировать с temperature, top_p и другими параметрами
- **Улучшение промптов**: На основе обратной связи агент корректирует свои системные промпты
- **Выбор стратегий**: Агент может выбирать разные подходы к решению задачи
- **Обучение на успехах**: Агент запоминает успешные паттерны работы

**Вопросы для проработки**:
- Нужны ли агентам внутренние метрики для MVP или это преждевременная оптимизация?
- Кто определяет метрики - разработчик агента или сам агент адаптивно?
- Как избежать ситуации, когда агент оптимизирует метрику в ущерб реальному качеству? (Goodhart's Law)
- Нужно ли логировать эволюцию агентов для прозрачности?
- Может ли человек "откатить" агента к предыдущему состоянию, если эволюция пошла не туда?

**Приоритет**: Низкий для MVP, высокий для продвинутых версий - интересная возможность для будущего

---

## 3. Process Cards (Карточки процессов)

### 3.1. Создание vs использование Process Cards

**Вопрос**: Когда Оркестратор создает новую Process Card, а когда использует существующую? По каким критериям?

**Связано с**: Вопрос 1.2 (Сопоставление задач и агентов)

**Приоритет**: Высокий - будет решаться при проектировании Process Cards

---

### 3.2. Checkpoints (Контрольные точки)

**Вопрос**: Как реализовать контрольные точки в Process Cards, где требуется подтверждение человека?

**Контекст**: Для некоторых задач критично, чтобы человек проверил промежуточный результат перед продолжением работы.

**Возможные варианты решения**:
- **Специальный тип шага в Process Card**: `type: "human_checkpoint"`
- **Автоматическая эскалация**: При достижении checkpoint система ставит процесс на паузу и уведомляет человека
- **Таймауты**: Если человек не ответил в течение N времени - действие по умолчанию (продолжить/остановить/эскалировать дальше)

**Связанные вопросы**:
- Как передать контекст человеку для принятия решения?
- Можно ли пропустить checkpoint в особых случаях?
- Как логировать решения человека для обучения системы?

**Приоритет**: Средний

---

### 3.3. Версионирование Process Cards

**Вопрос**: Как управлять версиями Process Cards? Если карточка улучшилась - как это версионировать?

**Контекст**: Process Cards будут эволюционировать - добавляться новые шаги, меняться критерии качества. Нужна система версионирования.

**Возможные варианты решения**:
- **Семантическое версионирование**: v1.0.0, v1.1.0, v2.0.0
- **Git-подобная система**: Коммиты, ветки, теги
- **История изменений**: Храним все версии с метаданными (кто изменил, когда, почему)
- **A/B тестирование**: Возможность запускать разные версии Process Card и сравнивать результаты

**Связанные вопросы**:
- Что происходит с запущенными задачами при обновлении Process Card?
- Можно ли откатиться к предыдущей версии?
- Как тестировать новые версии Process Cards?

**Приоритет**: Низкий - можно отложить на более поздние этапы

---

### 3.4. Intent (Намерение) задачи и бизнес-ценность

**Вопрос**: Должны ли Process Cards содержать не только процессную логику (КАК делать), но и стратегическую (ЗАЧЕМ делать)?

**Контекст**: В реальных бизнес-процессах важно понимать не только последовательность действий, но и цель - зачем эта задача вообще нужна, какую бизнес-ценность она приносит.

**Возможные элементы стратегической логики**:
- **Intent (Намерение)**: Зачем выполняется эта задача? Какая конечная цель?
- **Business Value (Бизнес-ценность)**: Какую ценность приносит результат? (для человека, для проекта, для компании)
- **Success Criteria (Критерии успеха)**: Как определить, что задача действительно достигла цели?
- **Assumptions (Предположения)**: Какие предположения лежат в основе процесса?
- **Risks (Риски)**: Что может пойти не так? Какие есть альтернативные сценарии?

**Как это помогает системе**:
- Оркестратор может понять, правильно ли сформулирована задача
- Система может предложить альтернативные пути достижения цели
- При изменении условий можно адаптировать процесс, сохраняя намерение
- Проще объяснить человеку, почему система приняла то или иное решение

**Вопросы для проработки**:
- Кто формулирует Intent - человек или Оркестратор на основе описания задачи?
- Может ли Оркестратор отклонить задачу, если не понимает Intent?
- Нужна ли валидация Intent перед началом выполнения?
- Как Intent влияет на выбор Process Card?

**Приоритет**: Средний - философски важно, но можно начать без этого

---

### 3.5. Система верификации и рейтинга Process Cards

**Вопрос**: Как система хранит и отображает метрики эффективности для каждой Process Card?

**Контекст**: В системе будет много Process Cards. Некоторые будут эффективны, другие нет. Нужна система рейтингов и метрик для выбора лучших процессов.

**Возможные метрики эффективности Process Card**:
- **Количество успешных выполнений**: Сколько раз процесс завершился успешно
- **Процент успеха**: Соотношение успешных выполнений к общему количеству
- **Средняя стоимость**: Сколько в среднем стоит выполнение (в токенах/деньгах)
- **Среднее время выполнения**: Как быстро в среднем завершается задача
- **Среднее количество итераций**: Сколько циклов улучшения требуется
- **Средняя оценка качества**: Какую оценку получают результаты
- **Оценка человека**: Насколько человек доволен результатами (если есть обратная связь)
- **Дата последнего использования**: Актуальность процесса
- **Версия**: Какая версия Process Card

**Как использовать рейтинг**:
- При выборе между несколькими подходящими Process Cards - выбрать с лучшим рейтингом
- Показывать пользователю самые эффективные процессы
- Архивировать неэффективные процессы
- Подготовка к будущей библиотеке/маркетплейсу Process Cards

**Вопросы для проработки**:
- Как комбинировать разные метрики в единый рейтинг?
- Нужна ли нормализация метрик? (Старые процессы vs новые)
- Можно ли давать Process Cards вручную (экспертная оценка)?
- Как учитывать контекст? (Процесс может быть эффективен для одних задач и неэффективен для других)

**Приоритет**: Средний - готовит почву для масштабирования библиотеки процессов

---

### 3.6. Долгоживущие процессы и типы задач

**Вопрос**: Как Process Cards описывают процессы, которые живут дни/недели и могут порождать другие процессы?

**Контекст**: Не все задачи атомарны и быстры. Некоторые процессы могут длиться долго, иметь подпроцессы, работать асинхронно.

**Типы процессов по длительности**:
- **Атомарные (секунды/минуты)**: Простая задача, выполняется быстро
- **Многошаговые (минуты/часы)**: Несколько последовательных шагов
- **Длительные (часы/дни)**: Процесс с большими перерывами, ожиданиями
- **Долгоживущие (дни/недели)**: Фоновые процессы, мониторинг, итеративные улучшения
- **Циклические (бесконечные)**: Постоянно работающие процессы (например, мониторинг трендов)

**Особенности долгоживущих процессов**:
- **Подпроцессы**: Процесс может порождать другие процессы
- **Асинхронные ожидания**: Процесс ждет внешнего события (ответ человека, доступность данных)
- **Возобновление**: Процесс может быть приостановлен и возобновлен позже
- **Промежуточные результаты**: Процесс выдает частичные результаты до завершения
- **Адаптивность**: Процесс может менять свою стратегию на основе промежуточных результатов

**Вопросы для проработки**:
- Как описывать подпроцессы в Process Card? (Вложенность, ссылки на другие карты?)
- Как управлять состоянием долгоживущего процесса?
- Нужна ли специальная система для мониторинга долгих задач?
- Как обрабатывать ситуацию, когда процесс "завис" в ожидании?
- Можно ли "убить" долгоживущий процесс без последствий?

**Приоритет**: Высокий - критично для реальных сценариев использования

---

## 4. MindBus (Шина данных)

### 4.1. Контекст и состояние задачи

**Вопрос**: Как передается контекст между агентами? Как избежать потери информации?

**Контекст**: Researcher собрал информацию → Writer написал текст → Editor проверяет. Каждый следующий агент должен иметь доступ к результатам предыдущих.

**Возможные варианты решения**:
- **Централизованное хранилище контекста**: Каждая задача имеет общее хранилище, доступное всем агентам
- **Передача через сообщения**: Результаты включаются в сообщения MindBus
- **Ссылочная модель**: Результаты хранятся в Storage, в сообщениях передаются только ссылки
- **Граф зависимостей**: Система строит граф задач и зависимостей, автоматически предоставляя нужный контекст

**Связанные вопросы**:
- Как управлять размером контекста (может быть очень большим)?
- Нужна ли "память" на уровне задачи?
- Как агенты запрашивают дополнительный контекст если нужно?
- Как долго хранится контекст завершенной задачи?

**Приоритет**: Высокий - критично для координации агентов

---

### 4.2. Надежность доставки сообщений

**Вопрос**: Как гарантировать надежную доставку сообщений? Что делать при сбоях?

**Связанные вопросы**:
- Нужна ли система подтверждений (acknowledgments)?
- Как обрабатывать недоступность агента?
- Нужны ли повторные попытки доставки?
- Как логировать все сообщения для аудита?

**Приоритет**: Высокий - будет решаться при проектировании MindBus

---

### 4.3. Определение "сообщения" и структура коммуникации

**Вопрос**: Что является сообщением в MindBus? Как выглядит контекст? Что такое цепочка сообщений?

**Контекст**: MindBus - это сердце всей системы. От правильного определения базовых концепций зависит вся архитектура.

**Нужно определить**:

**Что является сообщением?**
- Только команды? (Например: "Writer, создай текст")
- Команды + данные? (Команда + входные параметры)
- Команды + данные + метаданные? (+ приоритет, timeout, trace_id)
- События? (Например: "Задача завершена", "Агент изменил статус")
- Результаты? (Ответы агентов на команды)
- Запросы? (Агент запрашивает дополнительную информацию)

**Как выглядит контекст?**
- Контекст задачи (все данные, нужные для выполнения)
- Контекст агента (история его работы)
- Контекст диалога (переписка между агентами)
- Глобальный контекст (общее состояние системы)

**Что такое цепочка сообщений?**
- Последовательность связанных сообщений (request-response)
- Граф зависимостей (одно сообщение порождает несколько)
- Транзакция (группа сообщений, которые должны выполниться атомарно)

**Вопросы для проработки**:
- Какой формат сообщений? (JSON, Protocol Buffers, custom?)
- Какие обязательные поля должны быть в каждом сообщении?
- Как идентифицируются сообщения? (UUID, sequential ID, composite key?)
- Как сообщения связываются друг с другом? (correlation_id, parent_id, trace_id?)
- Нужна ли схема валидации сообщений?

**Приоритет**: Критический - основа всей коммуникации системы

---

### 4.4. Трассировка задач (Trace ID)

**Вопрос**: Как обеспечить полную трассируемость пути задачи через всю систему?

**Контекст**: Одна задача порождает десятки сообщений между Оркестратором, агентами, Storage. Нужно связать все эти операции для отладки и аудита.

**Возможные решения**:
- **Trace ID**: Уникальный идентификатор, присваиваемый задаче при создании
- **Распространение**: Trace ID передается во всех связанных сообщениях, логах, метриках
- **Correlation**: Все операции с одним Trace ID можно легко найти и визуализировать
- **Иерархия**: Span ID для подзадач внутри общей трассировки

**Что это дает**:
- Пользователь видит полную историю задачи "от и до"
- Разработчик может отладить цепочку вызовов
- Аудит: полная прозрачность того, что система делала

**Приоритет**: Высокий - критично для отладки и прозрачности

---

### 4.5. Точное определение типов сообщений MindBus

**Вопрос**: Сколько типов сообщений нужно системе? Как их назвать? Как реализовать технически?

**Контекст**: На концептуальном уровне определено, что сообщения имеют типы (Command, Result, Event, Query, Error, Control, Notification, Metric, Log, Stream и другие). Нужно принять финальные технические решения.

**Варианты решений**:

**Количество типов**:
- **Минималистичный подход**: 3-5 базовых типов (Command/Result/Event)
- **Сбалансированный подход**: 8-10 типов, покрывающих основные сценарии
- **Расширяемый подход**: 15-20 типов с резервом на будущее
- **Максимальная гибкость**: 1 байт на тип = 256 возможных значений

**Структура типизации**:
- **Плоская**: Один уровень типов (просто `COMMAND`, `RESULT`, etc.)
- **Иерархическая**: Type + Subtype (`COMMAND.STORE`, `COMMAND.RETRIEVE`, `EVENT.TASK_CREATED`, `EVENT.AGENT_ONLINE`)
- **Битовые флаги**: Возможность комбинировать типы (сообщение может быть одновременно Event и Notification)

**Техническая реализация**:
- **String enum**: `type: "COMMAND" | "RESULT" | "EVENT"` (гибко, но больше байт)
- **Integer enum**: `type: 1 | 2 | 3` (компактно, быстро)
- **Byte field**: 1 байт = 256 вариантов (баланс компактности и расширяемости)

**Именование**:
- **Английские имена**: COMMAND, RESULT, EVENT (универсально)
- **Короткие коды**: CMD, RES, EVT (компактно)
- **Семантические имена**: DO, DONE, HAPPENED (интуитивно)

**Что нужно решить**:
- Какие типы необходимы для MVP (минимальный жизнеспособный продукт)?
- Какие типы нужны для production (полнофункциональная система)?
- Нужна ли иерархия Type + Subtype или достаточно плоского списка?
- Как обеспечить расширяемость без breaking changes?
- Как версионировать схему типов при добавлении новых?

**Связанные решения**:
- Влияет на схему валидации payload (каждый тип может иметь свою схему)
- Влияет на роутинг в MindBus (маршрутизация по типу)
- Влияет на приоритезацию (разные типы могут иметь разный приоритет по умолчанию)
- Влияет на систему мониторинга (метрики по типам сообщений)

**Приоритет**: Высокий - фундаментальное решение, влияющее на протокол MindBus

---

## 5. Качество и улучшение

### 5.1. Оценка качества результатов

**Вопрос**: Как система оценивает качество результатов? Кто оценивает?

**Возможные варианты решения** (уже добавлены в README):
- **Экспертные агенты**: Специализированные агенты-валидаторы
- **Оркестратор**: Может оценивать как дополнительный эксперт
- **Коллегиальная оценка**: Несколько экспертов дают независимые оценки
- **Человек в контуре**: Финальная проверка человеком для критичных задач

**Критерии оценки**:
- Наличие ошибок
- Соответствие техническому заданию
- Мнение человека
- Метрики производительности
- Другие параметры из Process Card

**Связанные вопросы**:
- Как избежать ситуации, когда некачественный результат признается хорошим?
- Как обучать экспертных агентов оценке качества?
- Нужна ли градация качества (плохо/удовлетворительно/хорошо/отлично) или бинарная (годится/не годится)?

**Приоритет**: Критический - основа для циклов улучшения

---

### 5.2. Предотвращение бесконечных циклов доработки

**Вопрос**: Как система предотвращает бесконечные циклы улучшения? Когда остановиться?

**Контекст**: Риск "зависания" в попытках улучшить неулучшаемое, сжигая деньги на API-вызовы.

**Возможные варианты решения**:
- **Максимум итераций**: Жесткий лимит на количество циклов (например, не более 5 итераций)
- **Анализ прогресса**: Если качество перестало расти (было 50→60→80→90→90→90), значит достигнут верхний предел
- **Diminishing returns**: Если улучшение на последней итерации меньше порога (например, <5%), остановить
- **Эскалация человеку**: При достижении "плато" качества - запросить мнение человека
- **Стоимостный анализ**: Остановить если стоимость следующей итерации несоразмерна ожидаемому улучшению

**Связанные вопросы**:
- Как определяется "плато" качества?
- Можно ли в Process Card задавать разные стратегии остановки?
- Что делать если результат не достиг минимального порога качества даже после всех итераций?

**Приоритет**: Высокий - важно для экономичности

---

### 5.3. Обучение агентов и системы

**Вопрос**: Являются ли агенты stateless или они обучаются? Как система накапливает опыт?

**Возможные варианты решения**:
- **Stateless агенты**: Агенты не меняются, опыт накапливается только в Process Cards
- **Fine-tuning**: Периодическое дообучение моделей на успешных примерах
- **Промпт-инжиниринг**: Улучшение промптов агентов на основе опыта
- **База знаний**: Централизованная база лучших практик, доступная всем агентам

**Приоритет**: Средний - можно отложить на более поздние этапы

---

## 6. Бюджеты и ограничения

### 6.1. Task Budget (Бюджет задачи)

**Идея**: Каждая задача получает бюджет, чтобы предотвратить неконтролируемый расход ресурсов.

**Типы бюджета**:
- **Временной бюджет**: Максимальное время выполнения (например, 2 часа)
- **Финансовый бюджет**: Максимальная стоимость API-вызовов (например, $5)
- **Итерационный бюджет**: Максимальное количество циклов улучшения (например, 5 итераций)

**Вопросы**:
- Кто устанавливает бюджет - человек, Оркестратор или берется из Process Card?
- Что происходит при превышении бюджета - автоматическая остановка или запрос человеку?
- Можно ли динамически увеличивать бюджет?
- Нужен ли "запас" бюджета или строго по лимиту?

**Приоритет**: Высокий - важно для управления расходами

---

### 6.2. Финансовый мониторинг

**Вопрос**: Как отслеживать и контролировать расходы на AI API?

**Возможные варианты**:
- **Подсчет токенов**: Отслеживание использованных токенов для каждого агента и задачи
- **Стоимостные метрики**: Пересчет токенов в денежный эквивалент
- **Алерты**: Уведомления при приближении к лимитам
- **Отчеты**: Статистика расходов по задачам, агентам, периодам

**Приоритет**: Средний

---

## 7. Обработка ошибок и восстановление

### 7.1. Сбои и ошибки агентов

**Вопрос**: Что происходит при ошибках? Как система восстанавливается?

**Контекст**: Агент может упасть, AI может выдать некорректный ответ (галлюцинацию), могут быть проблемы с сетью.

**Возможные варианты решения**:
- **Retry механизмы**: Автоматические повторные попытки (с exponential backoff)
- **Fallback агенты**: Если агент недоступен - использовать альтернативного
- **Graceful degradation**: Система продолжает работать в ограниченном режиме
- **Эскалация**: При невозможности восстановить - сообщить человеку

**Связанные вопросы**:
- Как отличить временную ошибку от критической?
- Нужен ли circuit breaker pattern?
- Как логировать ошибки для последующего анализа?

**Приоритет**: Высокий - критично для надежности

---

### 7.2. Откаты (Rollback)

**Вопрос**: Есть ли возможность отката задачи к предыдущему состоянию?

**Контекст**: Если на каком-то шаге все пошло не так, нужно вернуться назад.

**Возможные варианты решения**:
- **Снапшоты состояния**: Сохранение состояния задачи на каждом важном шаге
- **Транзакционная модель**: ACID-гарантии для критических операций
- **Компенсирующие действия**: Вместо отката - выполнить действия, отменяющие эффект

**Приоритет**: Средний

---

### 7.3. Обработка галлюцинаций AI

**Вопрос**: Как обнаруживать и обрабатывать некорректные ответы AI (галлюцинации)?

**Возможные варианты решения**:
- **Кросс-проверка**: Несколько агентов решают одну задачу, результаты сравниваются
- **Валидация фактов**: Специальный агент проверяет фактическую корректность
- **Источники**: Требование указывать источники информации
- **Оценка уверенности**: AI указывает уровень уверенности в ответе

**Приоритет**: Высокий - критично для качества

---

## 8. Интерфейсы и взаимодействие

### 8.1. Асинхронность и длительные задачи

**Вопрос**: Как работает взаимодействие с человеком при длительных задачах (часы, дни)?

**Контекст**: Задача может длиться 2 часа, 2 дня или неделю. Человек не будет сидеть и ждать.

**Возможные решения**:
- **Промежуточные уведомления**: Отчеты о прогрессе на ключевых этапах/контрольных точках
- **Дашборд статуса**: Человек может в любой момент зайти и посмотреть текущее состояние
- **Push-уведомления**: Критические события приходят в Telegram/email
- **Асинхронная модель**: Человек ставит задачу и уходит, возвращается когда готово

**Связанные вопросы**:
- Как часто отправлять промежуточные уведомления?
- Нужна ли возможность "заморозить" задачу и вернуться позже?
- Как избежать спама уведомлениями?

**Приоритет**: Средний

---

### 8.2. Приоритизация уведомлений

**Вопрос**: Как правильно использовать систему приоритетов уведомлений?

**Уже есть в README**: 5 уровней (Critical, High, Medium, Low, Debug)

**Вопросы**:
- Кто определяет приоритет уведомления - агент или Оркестратор?
- Можно ли настраивать пороги уведомлений для разных каналов?
- Нужна ли агрегация уведомлений (digest)?

**Приоритет**: Низкий

---

## 9. Архитектура и технологии

### 9.1. Выбор технологического стека

**Вопрос**: Какие технологии использовать для реализации?

**Контекст**: Сейчас это концептуальный документ, технологии будут выбираться при детальном проектировании.

**Области для решения**:
- Язык программирования (Python, Node.js, Go, Rust?)
- MindBus реализация (RabbitMQ, Kafka, Redis Pub/Sub, custom?)
- Базы данных (PostgreSQL, MongoDB, Redis?)
- Хранилище файлов (S3, MinIO, локальная FS?)
- AI провайдеры (OpenAI, Anthropic, локальные модели?)

**Приоритет**: Будет решаться на этапе технического проектирования

---

### 9.2. Масштабируемость

**Вопрос**: Как система будет масштабироваться при росте нагрузки?

**Возможные подходы**:
- **Горизонтальное масштабирование**: Добавление новых инстансов агентов
- **Шардирование**: Распределение задач по разным серверам
- **Кластеризация**: MindBus и Orchestrator в кластере
- **Очереди**: Эффективное управление очередями задач

**Приоритет**: Низкий для MVP, высокий для production

---

## 10. Безопасность

### 10.1. Аутентификация и авторизация

**Вопрос**: Как защитить систему от несанкционированного доступа?

**Контекст**: В README указано, что в MVP "один пользователь - одна команда AI", но базовая защита нужна.

**Возможные решения**:
- **API ключи**: Для доступа к системе через API
- **Токены**: JWT токены для веб-интерфейса
- **Basic auth**: Простая защита паролем для MVP

**Приоритет**: Средний для MVP

---

### 10.2. Защита данных

**Вопрос**: Как защитить конфиденциальные данные пользователя?

**Связанные темы**:
- Шифрование данных в хранилище
- Шифрование в transit (HTTPS, TLS)
- Управление секретами (API ключи провайдеров)
- GDPR compliance (если планируется работа в EU)

**Приоритет**: Высокий

---

### 10.3. Безопасность процессов (защита от злоупотреблений)

**Вопрос**: Как защитить систему от процессов, которые могут навредить? (не только безопасность агентов, но и безопасность выполнения процессов)

**Контекст**: Даже если агенты изолированы, сами процессы могут создавать опасные ситуации: слишком дорогие операции, бесконечные циклы, DoS-атаки на собственную систему.

**Типы угроз от процессов**:

**Финансовые угрозы**:
- Процесс запрашивает слишком много вызовов API (огромные расходы)
- Бесконечный цикл улучшения без остановки
- Параллельный запуск десятков дорогих агентов

**Операционные угрозы**:
- Процесс порождает DoS-поток задач, забивая очереди
- Процесс создает циклические зависимости (deadlock)
- Процесс "зависает" и блокирует ресурсы навсегда

**Логические угрозы**:
- AI генерирует некорректные Process Cards с ошибками
- Процесс запрашивает конфиденциальные данные, к которым не должен иметь доступ
- Процесс пытается модифицировать критические системные настройки

**Возможные защитные механизмы**:
- **Бюджетные лимиты**: Жесткие ограничения на стоимость и время (уже в разделе 6.1)
- **Circuit Breaker**: Автоматическая остановка процесса при аномальном поведении
- **Rate Limiting**: Ограничение скорости создания задач/сообщений
- **Whitelist операций**: Процессы могут выполнять только разрешенные действия
- **Sandbox для Process Cards**: Новые процессы сначала выполняются в тестовом режиме
- **Мониторинг аномалий**: Автоматическое обнаружение странного поведения
- **Kill Switch**: Возможность экстренно остановить любой процесс

**Вопросы для проработки**:
- Кто определяет лимиты безопасности - человек, Оркестратор или система автоматически?
- Как система определяет "аномальное поведение" процесса?
- Нужен ли режим "read-only" для тестирования новых Process Cards?
- Как логировать попытки нарушения безопасности?
- Может ли процесс запросить увеличение лимитов? Кто это одобряет?

**Приоритет**: Высокий - критично для защиты от непредвиденных ситуаций

---

## 11. Тестирование и отладка

### 11.1. Тестирование Process Cards

**Вопрос**: Как тестировать Process Cards перед использованием в production?

**Возможные подходы**:
- **Dry-run режим**: Симуляция выполнения без реальных действий
- **Тестовые агенты**: Заглушки вместо реальных AI
- **Sandbox окружение**: Отдельная среда для экспериментов
- **Версионирование**: Тестирование новых версий параллельно со старыми

**Приоритет**: Средний

---

### 11.2. Отладка сложных процессов

**Вопрос**: Как отлаживать многошаговые процессы с множеством агентов?

**Возможные инструменты**:
- **Детальное логирование**: Все действия всех агентов
- **Трассировка**: Визуализация потока задач и сообщений
- **Replay**: Возможность "переиграть" выполнение задачи
- **Breakpoints**: Остановка процесса в определенных точках

**Приоритет**: Средний

---

## 12. Документация и примеры

### 12.1. Библиотека примеров Process Cards

**Вопрос**: Какие типовые Process Cards нужны для старта?

**Возможные примеры**:
- **Создание статьи**: Research → Write → Edit → Review
- **Разработка фичи**: Design → Code → Test → Review
- **Аналитический отчет**: Collect Data → Analyze → Visualize → Report

**Приоритет**: Средний - важно для onboarding пользователей

---

## 13. Каноническая модель данных и SSOT

### 13.1. Ключевые сущности системы

**Вопрос**: Какие ключевые сущности (entities) должны быть стандартизированы в системе?

**Контекст**: Для обеспечения единого источника правды необходимо определить базовые сущности, которые используются всеми компонентами системы.

**Возможные ключевые сущности**:
- **Task (Задача)**: Единица работы, которую выполняет система
- **Process (Процесс)**: Описание последовательности шагов для выполнения задачи
- **Agent (Агент)**: AI-сотрудник с определенной специализацией
- **Message (Сообщение)**: Единица коммуникации в MindBus
- **Artifact (Артефакт)**: Результат работы агента (файл, текст, данные)
- **Profile (Профиль)**: Описание агента (роль, компетенции, возможности)
- **Result (Результат)**: Структурированный ответ агента на задачу
- **Context (Контекст)**: Информация, необходимая для выполнения задачи
- **Event (Событие)**: Важное изменение в системе (смена статуса, ошибка и т.д.)

**Вопросы для проработки**:
- Какие поля должны быть в каждой сущности? (обязательные и опциональные)
- Как сущности связаны друг с другом? (связи и зависимости)
- Нужны ли базовые классы для сущностей? (например, все сущности имеют id, created_at, updated_at)
- Какие сущности могут расширяться кастомными полями, а какие строго фиксированы?

**Приоритет**: Критический - основа всей системы данных

---

### 13.2. Хранение и публикация схем данных

**Вопрос**: Где физически будут храниться схемы данных? Как они будут доступны всем компонентам?

**Контекст**: Схемы данных должны быть централизованы и доступны для всех разработчиков и всех компонентов системы во время выполнения.

**Возможные варианты решения**:
- **Файлы в репозитории**: JSON Schema, YAML файлы в отдельной папке `schemas/`
- **Отдельный модуль "Schema Registry"**: Специальный сервис, предоставляющий API для получения схем
- **Документация**: Схемы описаны в документации (Markdown, OpenAPI спецификация)
- **База данных**: Схемы хранятся в специальной таблице/коллекции в Storage Layer
- **Комбинированный подход**: Файлы в репозитории + автоматическая публикация в Schema Registry

**Вопросы для проработки**:
- Как компоненты получают актуальную версию схем?
- Нужно ли кэширование схем в каждом компоненте?
- Как обновлять схемы без остановки системы?
- Кто имеет право изменять схемы?

**Приоритет**: Высокий - инфраструктурное решение

---

### 13.3. Формат описания схем

**Вопрос**: Какой формат использовать для описания канонических схем данных?

**Контекст**: Формат должен быть понятным людям, машинно-читаемым и поддерживать валидацию.

**Возможные варианты**:
- **JSON Schema**: Стандарт для описания JSON структур, широкая поддержка
- **OpenAPI (Swagger)**: Стандарт для описания REST API, включает схемы данных
- **Protocol Buffers (protobuf)**: Бинарный формат от Google, строгая типизация
- **GraphQL Schema**: Язык описания схем от GraphQL
- **TypeScript interfaces**: Типы в коде, можно генерировать схемы
- **Custom DSL**: Собственный язык описания, максимальная гибкость

**Вопросы для проработки**:
- Нужна ли кроссплатформенность (разные языки программирования)?
- Важна ли строгая типизация или достаточно гибких схем?
- Нужна ли поддержка наследования и композиции схем?
- Как генерировать код/типы из схем автоматически?

**Приоритет**: Высокий - определяет технологический стек

---

### 13.4. Версионирование схем данных

**Вопрос**: Как управлять изменениями в канонических схемах? Как обеспечить обратную совместимость?

**Контекст**: Схемы будут эволюционировать - добавляться новые поля, меняться структуры. Нужна система версионирования.

**Возможные подходы**:
- **Семантическое версионирование**: MAJOR.MINOR.PATCH (например, Task v2.1.0)
- **Дата-версии**: YYYY-MM-DD (например, Task-2025-03-15)
- **Иммутабельные схемы**: Старые версии никогда не удаляются, новые создаются рядом
- **Правила совместимости**:
  - Добавление новых опциональных полей = MINOR версия
  - Удаление/переименование полей = MAJOR версия
  - Изменение типа поля = MAJOR версия

**Вопросы для проработки**:
- Как долго поддерживать старые версии схем?
- Как мигрировать данные при breaking changes?
- Нужен ли период deprecation перед удалением старой версии?
- Как тестировать совместимость версий?
- Что делать, если старый агент отправляет данные в старом формате?

**Приоритет**: Высокий - критично для эволюции системы

---

### 13.5. Валидация данных

**Вопрос**: Где и как происходит проверка данных на соответствие канонической схеме?

**Контекст**: Валидация должна предотвращать попадание некорректных данных в систему, но не создавать узких мест производительности.

**Возможные места валидации**:
- **В MindBus**: Все сообщения валидируются перед отправкой/получением
- **В API Gateway**: Валидация на входе в систему
- **В каждом компоненте**: Каждый агент/модуль валидирует свои входы и выходы
- **В Storage Layer**: Валидация перед сохранением в базу данных
- **Многоуровневая**: Комбинация нескольких мест

**Вопросы для проработки**:
- Что делать при обнаружении невалидных данных? (отклонить, логировать, пытаться исправить?)
- Нужна ли строгая валидация или допускаются "лишние" поля?
- Как логировать ошибки валидации для отладки?
- Влияет ли валидация на производительность? Нужно ли её отключать в production?

**Приоритет**: Высокий - защита от ошибок интеграции

---

### 13.6. Governance и управление изменениями

**Вопрос**: Кто отвечает за обновление канонической модели данных? Какой процесс утверждения изменений?

**Контекст**: Изменения в схемах данных влияют на все компоненты системы. Нужен управляемый процесс.

**Возможные процессы**:
- **Централизованный**: Один "владелец схем" (архитектор) утверждает все изменения
- **Децентрализованный**: Каждая команда может предлагать изменения через pull request
- **Комитет**: Группа экспертов рассматривает и утверждает изменения
- **Автоматический**: Изменения проходят автоматические тесты совместимости и применяются

**Вопросы для проработки**:
- Как предлагать изменения в схемы? (Issue, Pull Request, формальный RFC?)
- Нужен ли процесс ревью изменений?
- Как тестировать влияние изменений на существующие компоненты?
- Как документировать историю изменений схем?
- Нужна ли автоматическая генерация changelog для схем?

**Приоритет**: Средний - организационный процесс

---

### 13.7. Связь SSOT с другими компонентами

**Вопрос**: Как каноническая модель данных интегрируется с другими частями системы?

**Контекст**: SSOT должен быть встроен в работу всех компонентов естественным образом.

**Интеграция с компонентами**:
- **MindBus**: Передает сообщения в каноническом формате, валидирует структуру
- **Process Cards**: Описывают процессы над каноническими сущностями (Task, Result и т.д.)
- **Orchestrator**: Оперирует объектами из канонической модели
- **Агенты**: Принимают Task, возвращают Result в стандартном формате
- **Storage Layer**: Отражает ту же модель в терминах сущностей и связей
- **Интерфейсы**: Отображают данные согласно канонической модели

**Вопросы для проработки**:
- Нужен ли отдельный слой "Data Mapper" для преобразования между форматами?
- Как гарантировать, что все компоненты используют актуальные схемы?
- Можно ли автоматически генерировать клиентский код для работы со схемами?
- Нужны ли хелперы/библиотеки для работы с каноническими сущностями?

**Приоритет**: Высокий - архитектурная интеграция

---

## 14. Идеи для будущего

Идеи, которые интересны, но точно не для MVP:

### 14.1. A/B тестирование Process Cards
Возможность запускать разные версии процесса и сравнивать эффективность

### 14.2. Маркетплейс агентов и процессов
Публичный каталог готовых решений (уже отмечено в README как "не будет в MVP")

### 14.3. Визуальный редактор Process Cards
Drag-and-drop конструктор процессов (уже отмечено в README как "не будет в MVP")

### 14.4. Интеграции с популярными платформами
Готовые коннекторы к внешним сервисам (уже отмечено в README как "не будет в MVP")

### 14.5. Продвинутая аналитика
BI-дашборды, прогнозирование, рекомендации (уже отмечено в README как "не будет в MVP")

### 14.6. Мобильные нативные приложения
iOS и Android приложения (уже отмечено в README как "не будет в MVP")

### 14.7. Голосовое управление
Интеграция с голосовыми ассистентами

### 14.8. Collaborative mode
Несколько людей управляют одной AI-командой

### 14.9. Self-improving system
Система сама предлагает улучшения своей архитектуры

---

## Как работать с этим документом

1. **При начале работы над компонентом** - найти соответствующий раздел и проработать все вопросы
2. **При возникновении нового вопроса** - добавить его в соответствующий раздел
3. **При принятии решения** - пометить вопрос как ✅ и указать ссылку на документ с решением
4. **Регулярно просматривать** - чтобы не упустить важные детали

---

**Документ живой и постоянно обновляется по мере развития проекта.**
